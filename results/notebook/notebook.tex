\documentclass{article}

\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage{amsmath,amssymb}
\usepackage{parskip}
\usepackage{graphicx}
\usepackage{tikz}
\usetikzlibrary{shapes,positioning}
\usepackage{multicol}
\usepackage{listings}



%%%%%%%%%%%%%%%%%
%     Title     %
%%%%%%%%%%%%%%%%%
\title{Notebook}
\author{Fouad A.I. Azar}
\date{\today}

\begin{document}
\maketitle

\section*{Activities for 09-09-2023}
\subsection*{Creation of a Bash Script}
A new bash script was developed for the creation of a root directory to house the standard bioinformatics subdirectories. These subdirectories include \textit{bin}, \textit{src}, \textit{results}, \textit{doc}, and \textit{data}.

\subsection*{Development of a Python Script}
A Python script was written with the primary function of sending prompts to OpenAI. These prompts are mainly in relation to code updates and potential research ideas. Notably, the responses from these prompts together with the prompts themselves are stored in a PSQL database and individual text files. This practice ensures that the GPT information is meticulously recorded, providing a digital timeline of when, why and how the data was utilized.

\subsection*{Data Storage}
Photospectroscopic data and SMILES (Simplified Molecular Input Line Entry System) of chemical compounds were gathered into a CSV file named \textit{molecules.csv}. This file contains estimated data of about 25,000 rows and was stored in the \textit{data} subdirectory labelled with today's date.

\subsection*{Utilization of a Padel-Descriptor Python Script}
A Python script using a Padel-Descriptor tool is currently running to extract around 2,000 fields of data for the purpose of neural network training. There is an ongoing consideration to relocate this script into Mojo.

\section*{Acitivities for 10-09-2023}
\subsection*{Molecule Data Processing}
After running \texttt{padel.py} overnight, \texttt{2000 lines} of \texttt{molecules.csv} were processed, but not all were successfully interpreted due to \textit{run time errors}. To remedy this issue, an instance of \texttt{EC2} in \texttt{AWS} was created. The associated \texttt{.pem} file is located in the \texttt{bin} directory together with an executable bash script that opens the \texttt{EC2} instance named \texttt{Flurine}.

\subsection*{Mojo Exploration}
Performed some experimental explorations with \texttt{Mojo}. Since it lacks a list functionality, creating a neural network from scratch seemed more to be an exercise in futility than a scientific endeavor. 

\subsection*{Neural Network Class}
Developed a simple, modular neural network class in Python. However, with a million epochs it's failing to train as an \textit{exor}. It prompts the question of whether to allow it to run for longer.  

\subsection*{Master Thesis}
The master thesis was successfully downloaded and stored under \newline
\verb|~/MA/results/thesis/legacy|.\newline 
Utilizing \texttt{pdflatex} and \texttt{bibtex} to execute it produced no errors.

\section*{Activities for 11-09-2023}
Firstly, today I worked on writing Python scripts with the purpose of creating PSQL table for a file named \texttt{"descriptors.csv"}. During this task, I encountered a couple of challenges. The first problem arose when the number of descriptors calculated surpassed the limit of 1600 columns that PSQL can handle. 

The second issue was with the headers generated by Padel. These headers were not suitable for use in PSQL as they contained prohibited characters such as "-" and reserved terms like "As". 

To tackle these challenges, I developed two scripts. \texttt{sanitize\_headers.py} This script was created to sanitize the headers and make them usable in PSQL. \texttt{appendHeaders.py}: the purpose of this script is suggested by its name - it was designed to append headers. 

\section*{Activities for 12-09-2023}
\subsection*{Giving up on exporting to psql}
I initially considered using a psql table to organize my data, but the limitations in terms of column numbers and the sensitive nature of psql will result in a larger time investment than what is optimal for the project. Thus, I've decided to continue using .csv files instead.

\subsection*{Testing the Neural Network}
The neural network I coded was tested extensively. However, even after 100,000 epochs, the data is not properly converging. Two potential causes have been identified: 

\subsubsection*{Data Normalization} 
The data points may not be properly normalized or standardized, given that they are real numbers with no presumed fixed range. Further research will be conducted to understand how to improve data normalization for this specific case and how the PaDEL descriptor calculates, which might influence decision on normalization.

\subsubsection*{Architecture and Activation Functions}
There could be faults in the architecture and choice of activation functions. The current setup is [len(x),1024][1024,512][512,256][256.128][128,1], with each layer using a Rectified Linear Unit (ReLU) as its activation function. Further investigation is required to identify the most suitable architecture and activation functions for this type of application.

\subsection*{Data Distribution}
Histograms were created to observe the distribution of emission maxima and molecular weights. However, I will be redoing all of this again when I have the complete dataset.

\section*{Activities for 13-09-2023}
\subsection*{Data Generation Pipeline}
I have successfully created a pipeline for generating our training data. This simplifies the process, obviating the need for multiple scripts to prepare the data. The pipeline operates as follows:

\begin{enumerate}
    \item Extract descriptors without fingerprints from \texttt{molecules.csv}. This process is separated due to the intensive computational need which might take days using a simple laptop without a GPU. This creates a new file named \texttt{descriptors.csv}, which will be automatically duplicated into \texttt{descriptors\_backup.csv}. The current copy is located at \texttt{\~/MA/data/2023-09-10/}, while the \texttt{molecules.csv} is at \texttt{\~/MA/data/2023-09-09}.
    
    \item Append headers to \texttt{descriptor\_backup.csv}. This is due to a flaw with the \texttt{to\_csv} function from the library padelpy that doesn't export CSV files with headers. To execute this, you'll need \texttt{headers.csv} in the same directory as the script.
    
    \item Match the tags between the descriptors and molecules to identify which rows have been processed. This can be problematic because of padelpy's \texttt{from\_smiles} function's long runtime. My \texttt{padel.py} script has a try and catch so that the extraction for each smile goes uninterrupted. The output CSV will contain all the rows from descriptors plus the target "Emission max (nm)" from \texttt{molecules.csv}.
    
    \item Lastly, apply a mask to remove all NaN's. This is important in case there is a target output with no value. 
\end{enumerate}

All of these processes are located under \texttt{\~/MA/src/pipeline/main.py}.

\subsection*{Neural Network Training}
I have completed the first successful neural network training process. I used tensorflow to test if my hypothesis would yield a positive correlation between the predicted and experimental values of the emission maximum.

\subsection*{Histograms}
Finally, I created some histograms to visualise the distribution of emission maxima and molecular weight. However, these need to be updated again once the EC2 instance is done calculating the PaDEL descriptors.


\end{document}
